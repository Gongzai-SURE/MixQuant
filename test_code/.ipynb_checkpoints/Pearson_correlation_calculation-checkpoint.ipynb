{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53812c06-ae78-46e3-ac9a-d5313fe1356c",
   "metadata": {},
   "source": [
    "# 计算完整数组的皮尔逊相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39139ce4-92b0-4611-add8-ee1accdcf4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import re\n",
    "\n",
    "def cal_all_data_pearson(filename1,filename2,rootpath=\"/root/autodl-tmp/methods/mix_quantize/model_info/llama2-7b/\"):\n",
    "    with open(rootpath+filename1, 'r') as f:\n",
    "        data1 = json.load(f)\n",
    "    \n",
    "    with open(rootpath+filename2, 'r') as f:\n",
    "        data2 = json.load(f)\n",
    "    \n",
    "    # 将数据转换为 DataFrame 格式\n",
    "    df1 = pd.DataFrame(data1).T  # 转置以确保行代表样本\n",
    "    df2 = pd.DataFrame(data2).T\n",
    "    \n",
    "    # 将两组数据展平为一维数组\n",
    "    flat_data1 = df1.values.flatten()\n",
    "    flat_data2 = df2.values.flatten()\n",
    "    # print(flat_data1)\n",
    "    # print(flat_data2)\n",
    "    csv_data = pd.DataFrame({\n",
    "                            'flat_data1': flat_data1,\n",
    "                            'flat_data2': flat_data2\n",
    "                            })\n",
    "    csv_path = rootpath + 'flattened_data.csv'\n",
    "    csv_data.to_csv(csv_path, index=False)\n",
    "\n",
    "    # 计算总体皮尔逊相关系数\n",
    "    corr, p_value = pearsonr(flat_data1, flat_data2)\n",
    "     \n",
    "    # 输出结果\n",
    "    print(f\"Pearson Correlation Coefficient: {corr:.4f}\")\n",
    "    print(f\"Two-tailed p-value: {p_value:.4e}\")\n",
    "    \n",
    "    # 检验显著性\n",
    "    alpha = 0.05  # 显著性水平\n",
    "    if p_value < alpha:\n",
    "        print(\"The correlation is statistically significant.\")\n",
    "    else:\n",
    "        print(\"The correlation is not statistically significant.\")\n",
    "\n",
    "def cal_all_data_pearson_with_difference(filename1,filename2,rootpath=\"/root/autodl-tmp/methods/mix_quantize/model_info/llama2-7b/\"):\n",
    "    with open(rootpath+filename1, 'r') as f:\n",
    "        data1 = json.load(f)\n",
    "    \n",
    "    with open(rootpath+filename2, 'r') as f:\n",
    "        data2 = json.load(f)\n",
    "\n",
    "    original_perplexity = float(re.search(r\"(\\d+\\.\\d+)\", filename2).group(1))\n",
    "    \n",
    "    # 将数据转换为 DataFrame 格式\n",
    "    df1 = pd.DataFrame(data1).T  # 转置以确保行代表样本\n",
    "    df2 = pd.DataFrame(data2).T \n",
    "    \n",
    "    # 将两组数据展平为一维数组\n",
    "    flat_data1 = df1.values.flatten()\n",
    "    flat_data2 = df2.values.flatten() - original_perplexity\n",
    "    \n",
    "    # 计算总体皮尔逊相关系数\n",
    "    corr, p_value = pearsonr(flat_data1, flat_data2)\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"Pearson Correlation Coefficient: {corr:.4f}\")\n",
    "    print(f\"Two-tailed p-value: {p_value:.4e}\")\n",
    "    \n",
    "    # 检验显著性\n",
    "    alpha = 0.05  # 显著性水平\n",
    "    if p_value < alpha:\n",
    "        print(\"The correlation is statistically significant.\")\n",
    "    else:\n",
    "        print(\"The correlation is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4b87f2-b9cc-4553-98b6-6157a84cda12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient: 0.1961\n",
      "Two-tailed p-value: 3.2023e-03\n",
      "The correlation is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"fisher_data_1024_2_2024-12-21-15-55-27.json\"\n",
    "filename2 = \"modified_perplexitys_1024_2_2024-12-21-15-55-27_2.7421875.json\"\n",
    "cal_all_data_pearson(filename1,filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb10ebef-db06-4d66-bad7-b3c494650330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Pearson Correlation: 0.1961\n"
     ]
    }
   ],
   "source": [
    "cal_all_data_pearson_with_difference(filename1,filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96901e85-c52a-4b5d-8e2e-7f73ae17602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Pearson Correlation: -0.0364\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"fisher_data_1024_10_2024-12-21-16-44-29.json\"\n",
    "filename2 = \"modified_perplexitys_1024_10_2024-12-21-16-44-29_2.60546875.json\"\n",
    "cal_all_data_pearson(filename1,filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d135758-bc50-4a7c-96fb-b6886a6b9c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Pearson Correlation: 0.2216\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"fisher_data_4096_20_2024-12-21-15-40-48.json\"\n",
    "filename2 = \"modified_perplexitys_4096_20_2024-12-21-15-40-48_2.44140625.json\"\n",
    "cal_all_data_pearson(filename1,filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f1229-4a5e-4b1a-af44-ab3f2a45407a",
   "metadata": {},
   "source": [
    "# 计算每个key的皮尔逊值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d47e252-59d1-4d94-913b-19128ae82d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def cal_key_pearson(filename1,filename2,rootpath=\"/root/autodl-tmp/methods/mix_quantize/model_info/llama2-7b/\"):\n",
    "    with open(rootpath+filename1, 'r') as f:\n",
    "        data1 = json.load(f)[\"0\"]\n",
    "    \n",
    "    with open(rootpath+filename2, 'r') as f:\n",
    "        data2 = json.load(f)[\"0\"]\n",
    "        \n",
    "    # 将数据转换为 DataFrame 格式\n",
    "    df1 = pd.DataFrame(data1).T  # 转置以确保行代表样本\n",
    "    df2 = pd.DataFrame(data2).T\n",
    "    \n",
    "    # 对应列计算皮尔逊相关性\n",
    "    correlation_results = {}\n",
    "    for column in df1.columns:\n",
    "        if column in df2.columns:\n",
    "            corr, _ = pearsonr(df1[column], df2[column])\n",
    "            correlation_results[column] = corr\n",
    "    \n",
    "    # 输出结果\n",
    "    for key, value in correlation_results.items():\n",
    "        print(f\"Column: {key}, Pearson Correlation: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf32aaa3-a343-484f-b130-85ab292adb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: self_attn.q_proj.weight, Pearson Correlation: 0.4893\n",
      "Column: self_attn.k_proj.weight, Pearson Correlation: 0.0602\n",
      "Column: self_attn.v_proj.weight, Pearson Correlation: -0.0854\n",
      "Column: self_attn.o_proj.weight, Pearson Correlation: 0.1791\n",
      "Column: mlp.gate_proj.weight, Pearson Correlation: 0.2548\n",
      "Column: mlp.up_proj.weight, Pearson Correlation: 0.1098\n",
      "Column: mlp.down_proj.weight, Pearson Correlation: 0.2691\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"fisher_data_1024_2_2024-12-21-15-55-27.json\"\n",
    "filename2 = \"modified_perplexitys_1024_2_2024-12-21-15-55-27_2.7421875.json\"\n",
    "cal_key_pearson(filename1,filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a427c976-70af-48ef-930a-c0cba3f40f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: self_attn.q_proj.weight, Pearson Correlation: 0.1740\n",
      "Column: self_attn.k_proj.weight, Pearson Correlation: 0.4538\n",
      "Column: self_attn.v_proj.weight, Pearson Correlation: -0.1413\n",
      "Column: self_attn.o_proj.weight, Pearson Correlation: 0.0323\n",
      "Column: mlp.gate_proj.weight, Pearson Correlation: 0.3305\n",
      "Column: mlp.up_proj.weight, Pearson Correlation: 0.3184\n",
      "Column: mlp.down_proj.weight, Pearson Correlation: 0.4135\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"fisher_data_4096_20_2024-12-21-15-40-48.json\"\n",
    "filename2 = \"modified_perplexitys_4096_20_2024-12-21-15-40-48_2.44140625.json\"\n",
    "cal_key_pearson(filename1,filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da63479b-48f1-4da0-8e0a-a2abe70d330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: self_attn.q_proj, Pearson Correlation: 0.2881\n",
      "Column: self_attn.k_proj, Pearson Correlation: 0.0377\n",
      "Column: self_attn.v_proj, Pearson Correlation: 0.1300\n",
      "Column: self_attn.o_proj, Pearson Correlation: 0.1302\n",
      "Column: mlp.gate_proj, Pearson Correlation: 0.1258\n",
      "Column: mlp.up_proj, Pearson Correlation: 0.1269\n",
      "Column: mlp.down_proj, Pearson Correlation: 0.1360\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"fisher_data_1024_2_2024-12-23-14-07-30.json\"\n",
    "filename2 = \"modified_perplexitys_1024_2_2024-12-23-14-07-30_2.7421875.json\"\n",
    "cal_key_pearson(filename1,filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4452183b-2733-4fa5-8390-d86d7f8a5141",
   "metadata": {},
   "source": [
    "# 绘制不同位宽设定下的结果表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17059fb2-f0f9-4fcb-92ee-6a51a80d0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "rootpath=\"/root/autodl-tmp/methods/mix_quantize/model_info/llama2-7b/\"\n",
    "# Load the data from the provided files\n",
    "with open(rootpath+'fisher_data_1024_2_2024-12-22-19-12-03.json', 'r') as f:\n",
    "    fisher_data = json.load(f)\n",
    "with open(rootpath+'modified_perplexitys_1024_2_2024-12-22-19-12-03_2.7421875.json', 'r') as f:\n",
    "    perplexity_data = json.load(f)\n",
    "\n",
    "# 假设数据已经按照量化位宽 -> block_id -> layer_name组织\n",
    "# reorganized_fisher_data = {width: {block_id: fisher_data[block_id] for block_id in fisher_data.keys()} for width, fisher_data in zip(bit_widths, fisher_data.values())}\n",
    "# reorganized_perplexity_data = {width: {block_id: perplexity_data[block_id] for block_id in perplexity_data.keys()} for width, perplexity_data in zip(bit_widths, perplexity_data.values())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9803c7b3-22ff-4c44-99cb-ff22c508601a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Block ID</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Width 8 (Fisher, Perplexity)</th>\n",
       "      <th>Width 4 (Fisher, Perplexity)</th>\n",
       "      <th>Width 3 (Fisher, Perplexity)</th>\n",
       "      <th>Width 2 (Fisher, Perplexity)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>self_attn.q_proj</td>\n",
       "      <td>(0.46, 2.74219)</td>\n",
       "      <td>(0.41, 2.74414)</td>\n",
       "      <td>(0.34, 2.74219)</td>\n",
       "      <td>(0.69, 2.74219)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>self_attn.k_proj</td>\n",
       "      <td>(4.75, 2.74219)</td>\n",
       "      <td>(4.80, 2.74219)</td>\n",
       "      <td>(4.59, 2.74219)</td>\n",
       "      <td>(4.91, 2.74414)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>self_attn.v_proj</td>\n",
       "      <td>(1.29, 2.74219)</td>\n",
       "      <td>(1.22, 2.74219)</td>\n",
       "      <td>(1.27, 2.74609)</td>\n",
       "      <td>(894.50, 2.85547)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>self_attn.o_proj</td>\n",
       "      <td>(1.13, 2.74219)</td>\n",
       "      <td>(1.12, 2.74219)</td>\n",
       "      <td>(1.04, 2.74219)</td>\n",
       "      <td>(1.20, 2.74609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>mlp.gate_proj</td>\n",
       "      <td>(0.98, 2.74219)</td>\n",
       "      <td>(0.99, 2.74414)</td>\n",
       "      <td>(0.96, 2.74219)</td>\n",
       "      <td>(1.13, 2.74609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>mlp.up_proj</td>\n",
       "      <td>(1.24, 2.74219)</td>\n",
       "      <td>(1.25, 2.74219)</td>\n",
       "      <td>(1.22, 2.74414)</td>\n",
       "      <td>(1.24, 2.74414)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>mlp.down_proj</td>\n",
       "      <td>(1.16, 2.74219)</td>\n",
       "      <td>(1.20, 2.74414)</td>\n",
       "      <td>(1.17, 2.74414)</td>\n",
       "      <td>(1.27, 2.74609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>self_attn.q_proj</td>\n",
       "      <td>(0.67, 2.74219)</td>\n",
       "      <td>(0.67, 2.74219)</td>\n",
       "      <td>(0.68, 2.74414)</td>\n",
       "      <td>(0.54, 2.73828)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>self_attn.k_proj</td>\n",
       "      <td>(0.97, 2.74219)</td>\n",
       "      <td>(0.97, 2.74414)</td>\n",
       "      <td>(1.04, 2.74219)</td>\n",
       "      <td>(1.31, 2.74609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>self_attn.v_proj</td>\n",
       "      <td>(1.26, 2.74414)</td>\n",
       "      <td>(1.41, 2.74609)</td>\n",
       "      <td>(1.70, 2.74609)</td>\n",
       "      <td>(3.34, 2.74609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>self_attn.o_proj</td>\n",
       "      <td>(1.00, 2.74219)</td>\n",
       "      <td>(1.05, 2.74219)</td>\n",
       "      <td>(1.01, 2.74609)</td>\n",
       "      <td>(1.51, 2.74414)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>mlp.gate_proj</td>\n",
       "      <td>(0.95, 2.74219)</td>\n",
       "      <td>(0.93, 2.74219)</td>\n",
       "      <td>(0.95, 2.74219)</td>\n",
       "      <td>(1.09, 2.74609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>mlp.up_proj</td>\n",
       "      <td>(1.08, 2.74219)</td>\n",
       "      <td>(1.09, 2.74219)</td>\n",
       "      <td>(0.85, 2.74219)</td>\n",
       "      <td>(1.15, 2.75000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>mlp.down_proj</td>\n",
       "      <td>(1.09, 2.74414)</td>\n",
       "      <td>(0.86, 2.74414)</td>\n",
       "      <td>(0.52, 2.73438)</td>\n",
       "      <td>(0.71, 2.75391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>self_attn.q_proj</td>\n",
       "      <td>(1.31, 2.74219)</td>\n",
       "      <td>(1.33, 2.74219)</td>\n",
       "      <td>(1.30, 2.74414)</td>\n",
       "      <td>(1.37, 2.73828)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>self_attn.k_proj</td>\n",
       "      <td>(1.32, 2.74219)</td>\n",
       "      <td>(1.40, 2.74219)</td>\n",
       "      <td>(1.38, 2.74219)</td>\n",
       "      <td>(1.37, 2.74219)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>self_attn.v_proj</td>\n",
       "      <td>(1.04, 2.74219)</td>\n",
       "      <td>(1.03, 2.74414)</td>\n",
       "      <td>(0.97, 2.75000)</td>\n",
       "      <td>(1.08, 2.74609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>self_attn.o_proj</td>\n",
       "      <td>(0.86, 2.74219)</td>\n",
       "      <td>(0.85, 2.74219)</td>\n",
       "      <td>(0.84, 2.73828)</td>\n",
       "      <td>(0.86, 2.73828)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>mlp.gate_proj</td>\n",
       "      <td>(1.21, 2.74219)</td>\n",
       "      <td>(1.26, 2.74414)</td>\n",
       "      <td>(1.06, 2.74219)</td>\n",
       "      <td>(1.27, 2.74609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>mlp.up_proj</td>\n",
       "      <td>(1.14, 2.74219)</td>\n",
       "      <td>(1.12, 2.74219)</td>\n",
       "      <td>(1.20, 2.74219)</td>\n",
       "      <td>(1.27, 2.74609)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>mlp.down_proj</td>\n",
       "      <td>(1.03, 2.74219)</td>\n",
       "      <td>(1.00, 2.74219)</td>\n",
       "      <td>(1.16, 2.74414)</td>\n",
       "      <td>(0.87, 2.74609)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Block ID        Layer Name Width 8 (Fisher, Perplexity)  \\\n",
       "0         0  self_attn.q_proj              (0.46, 2.74219)   \n",
       "1         0  self_attn.k_proj              (4.75, 2.74219)   \n",
       "2         0  self_attn.v_proj              (1.29, 2.74219)   \n",
       "3         0  self_attn.o_proj              (1.13, 2.74219)   \n",
       "4         0     mlp.gate_proj              (0.98, 2.74219)   \n",
       "5         0       mlp.up_proj              (1.24, 2.74219)   \n",
       "6         0     mlp.down_proj              (1.16, 2.74219)   \n",
       "7         1  self_attn.q_proj              (0.67, 2.74219)   \n",
       "8         1  self_attn.k_proj              (0.97, 2.74219)   \n",
       "9         1  self_attn.v_proj              (1.26, 2.74414)   \n",
       "10        1  self_attn.o_proj              (1.00, 2.74219)   \n",
       "11        1     mlp.gate_proj              (0.95, 2.74219)   \n",
       "12        1       mlp.up_proj              (1.08, 2.74219)   \n",
       "13        1     mlp.down_proj              (1.09, 2.74414)   \n",
       "14        2  self_attn.q_proj              (1.31, 2.74219)   \n",
       "15        2  self_attn.k_proj              (1.32, 2.74219)   \n",
       "16        2  self_attn.v_proj              (1.04, 2.74219)   \n",
       "17        2  self_attn.o_proj              (0.86, 2.74219)   \n",
       "18        2     mlp.gate_proj              (1.21, 2.74219)   \n",
       "19        2       mlp.up_proj              (1.14, 2.74219)   \n",
       "20        2     mlp.down_proj              (1.03, 2.74219)   \n",
       "\n",
       "   Width 4 (Fisher, Perplexity) Width 3 (Fisher, Perplexity)  \\\n",
       "0               (0.41, 2.74414)              (0.34, 2.74219)   \n",
       "1               (4.80, 2.74219)              (4.59, 2.74219)   \n",
       "2               (1.22, 2.74219)              (1.27, 2.74609)   \n",
       "3               (1.12, 2.74219)              (1.04, 2.74219)   \n",
       "4               (0.99, 2.74414)              (0.96, 2.74219)   \n",
       "5               (1.25, 2.74219)              (1.22, 2.74414)   \n",
       "6               (1.20, 2.74414)              (1.17, 2.74414)   \n",
       "7               (0.67, 2.74219)              (0.68, 2.74414)   \n",
       "8               (0.97, 2.74414)              (1.04, 2.74219)   \n",
       "9               (1.41, 2.74609)              (1.70, 2.74609)   \n",
       "10              (1.05, 2.74219)              (1.01, 2.74609)   \n",
       "11              (0.93, 2.74219)              (0.95, 2.74219)   \n",
       "12              (1.09, 2.74219)              (0.85, 2.74219)   \n",
       "13              (0.86, 2.74414)              (0.52, 2.73438)   \n",
       "14              (1.33, 2.74219)              (1.30, 2.74414)   \n",
       "15              (1.40, 2.74219)              (1.38, 2.74219)   \n",
       "16              (1.03, 2.74414)              (0.97, 2.75000)   \n",
       "17              (0.85, 2.74219)              (0.84, 2.73828)   \n",
       "18              (1.26, 2.74414)              (1.06, 2.74219)   \n",
       "19              (1.12, 2.74219)              (1.20, 2.74219)   \n",
       "20              (1.00, 2.74219)              (1.16, 2.74414)   \n",
       "\n",
       "   Width 2 (Fisher, Perplexity)  \n",
       "0               (0.69, 2.74219)  \n",
       "1               (4.91, 2.74414)  \n",
       "2             (894.50, 2.85547)  \n",
       "3               (1.20, 2.74609)  \n",
       "4               (1.13, 2.74609)  \n",
       "5               (1.24, 2.74414)  \n",
       "6               (1.27, 2.74609)  \n",
       "7               (0.54, 2.73828)  \n",
       "8               (1.31, 2.74609)  \n",
       "9               (3.34, 2.74609)  \n",
       "10              (1.51, 2.74414)  \n",
       "11              (1.09, 2.74609)  \n",
       "12              (1.15, 2.75000)  \n",
       "13              (0.71, 2.75391)  \n",
       "14              (1.37, 2.73828)  \n",
       "15              (1.37, 2.74219)  \n",
       "16              (1.08, 2.74609)  \n",
       "17              (0.86, 2.73828)  \n",
       "18              (1.27, 2.74609)  \n",
       "19              (1.27, 2.74609)  \n",
       "20              (0.87, 2.74609)  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个用于存储结果的列表\n",
    "bit_widths = [8,4,3,2]\n",
    "reorganized_results = []\n",
    "\n",
    "for block_id in fisher_data[\"8\"].keys():  # 假设 \"8\" 是一个示例位宽\n",
    "    for layer in fisher_data[\"8\"][block_id].keys():\n",
    "        row = {\"Block ID\": block_id, \"Layer Name\": layer}\n",
    "        for width in bit_widths:\n",
    "            fisher_value = fisher_data.get(f\"{width}\", {}).get(block_id, {}).get(layer)\n",
    "            perplexity_value = perplexity_data.get(f\"{width}\", {}).get(block_id, {}).get(layer)\n",
    "                     \n",
    "            if fisher_value is not None and perplexity_value is not None:\n",
    "                row[f\"Width {width} (Fisher, Perplexity)\"] = (\"{:.2f}\".format(fisher_value), \"{:.5f}\".format(perplexity_value))\n",
    "            else:\n",
    "                row[f\"Width {width} (Fisher, Perplexity)\"] = (None, None)  # 处理缺失值\n",
    "        \n",
    "        reorganized_results.append(row)\n",
    "\n",
    "\n",
    "# 创建DataFrame\n",
    "df_reorganized = pd.DataFrame(reorganized_results)\n",
    "\n",
    "# 查看表格的前几行\n",
    "df_reorganized.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad05f71-031e-454b-abe6-6777325a6733",
   "metadata": {},
   "source": [
    "# 量化位宽与fisher info 以及 量化位宽和困惑度变化的相关系数计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2938e7-7e43-4f0d-8c16-fc2a060a138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import re\n",
    "\n",
    "def cal_bits2fisher_pearson(filename,rootpath=\"/root/autodl-tmp/methods/mix_quantize/model_info/llama2-7b/\"):\n",
    "    with open(rootpath+filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    bitwidths = [2, 3, 4, 8]\n",
    "    results = {}\n",
    "\n",
    "    for key in data[\"8\"][str(0)].keys():  # 获取所有key（假设每个block都有相同的key）\n",
    "        # 对于每个量化位宽，计算对应key层在32个block_id上的平均值\n",
    "        avg_fisher_values = []\n",
    "        \n",
    "        for bw in bitwidths:\n",
    "            fisher_values_for_bw = []\n",
    "            \n",
    "            # 收集所有block_id中该量化位宽下的Fisher信息\n",
    "            for block_id in range(32):\n",
    "                fisher_values_for_bw.append(data[str(bw)][str(block_id)][key])\n",
    "            \n",
    "            # 计算该量化位宽下的平均Fisher信息\n",
    "            avg_fisher = sum(fisher_values_for_bw) / len(fisher_values_for_bw)\n",
    "            avg_fisher_values.append(avg_fisher)\n",
    "        \n",
    "        # 计算量化位宽和平均Fisher信息之间的皮尔逊相关系数及p-value\n",
    "        corr, p_value = pearsonr(bitwidths*32, avg_fisher_values*32)\n",
    "\n",
    "        print(avg_fisher_values)\n",
    "        \n",
    "        # 保存该key的结果\n",
    "        results[key] = {\n",
    "            \"corr\": corr,\n",
    "            \"p_value\": p_value\n",
    "        }\n",
    "        \n",
    "    df = pd.DataFrame(results).T\n",
    "    # 输出结果\n",
    "    print(df.head(7))\n",
    "\n",
    "def cal_bits2perplexity_pearson(filename,rootpath=\"/root/autodl-tmp/methods/mix_quantize/model_info/llama2-7b/\"):\n",
    "    with open(rootpath+filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    bitwidths = [2, 3, 4, 8]\n",
    "    results = {}\n",
    "\n",
    "    for key in data[\"8\"][str(0)].keys():  # 获取所有key（假设每个block都有相同的key）\n",
    "        # 对于每个量化位宽，计算对应key层在32个block_id上的平均值\n",
    "        avg_ple_values = []\n",
    "        \n",
    "        for bw in bitwidths:\n",
    "            ple_values_for_bw = []\n",
    "            \n",
    "            # 收集所有block_id中该量化位宽下的Fisher信息\n",
    "            for block_id in range(32):\n",
    "                ple_values_for_bw.append(data[str(bw)][str(block_id)][key])\n",
    "            \n",
    "            # 计算该量化位宽下的平均Fisher信息\n",
    "            avg_ple = sum(ple_values_for_bw) / len(ple_values_for_bw)\n",
    "            avg_ple_values.append(avg_ple)\n",
    "\n",
    "        print(avg_ple_values)\n",
    "        \n",
    "        # 计算量化位宽和平均Fisher信息之间的皮尔逊相关系数及p-value\n",
    "        corr, p_value = pearsonr(bitwidths*32, avg_ple_values*32)\n",
    "        \n",
    "        # 保存该key的结果\n",
    "        results[key] = {\n",
    "            \"corr\": corr,\n",
    "            \"p_value\": p_value\n",
    "        }\n",
    "        \n",
    "    df = pd.DataFrame(results).T\n",
    "    # 输出结果\n",
    "    print(df.head(7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1609d85-89d8-43ae-ae80-174d9e3db6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.33563232421875, 1.2452621459960938, 1.2432327270507812, 1.23663330078125]\n",
      "[1.45599365234375, 1.3392333984375, 1.3439178466796875, 1.3390655517578125]\n",
      "[29.12786865234375, 1.1214599609375, 1.084869384765625, 1.0731964111328125]\n",
      "[1.1143646240234375, 1.1068878173828125, 1.1125335693359375, 1.115203857421875]\n",
      "[1.164154052734375, 1.1173248291015625, 1.1090240478515625, 1.107513427734375]\n",
      "[1.1347503662109375, 1.1279144287109375, 1.15338134765625, 1.151123046875]\n",
      "[2.568939208984375, 1.141204833984375, 1.0986328125, 1.1203460693359375]\n",
      "                      corr       p_value\n",
      "self_attn.q_proj -0.632796  1.118280e-15\n",
      "self_attn.k_proj -0.581320  6.264712e-13\n",
      "self_attn.v_proj -0.571330  1.887489e-12\n",
      "self_attn.o_proj  0.438540  2.247970e-07\n",
      "mlp.gate_proj    -0.662916  1.540007e-17\n",
      "mlp.up_proj       0.665661  1.016812e-17\n",
      "mlp.down_proj    -0.573687  1.459922e-12\n",
      "----------------------------------------\n",
      "                      corr       p_value\n",
      "self_attn.q_proj -0.884251  1.732190e-43\n",
      "self_attn.k_proj -0.917151  3.526569e-52\n",
      "self_attn.v_proj -0.761516  1.728182e-25\n",
      "self_attn.o_proj -0.811218  3.781759e-31\n",
      "mlp.gate_proj    -0.717476  1.608838e-21\n",
      "mlp.up_proj      -0.699258  4.318466e-20\n",
      "mlp.down_proj    -0.612742  1.509229e-14\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"fisher_data_1024_2_2024-12-22-19-12-03.json\"\n",
    "filename2 = \"modified_perplexitys_1024_2_2024-12-22-19-12-03_2.7421875.json\"\n",
    "cal_bits2fisher_pearson(filename1)\n",
    "print(\"----\"*10)\n",
    "cal_bits2perplexity_pearson(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9248d577-729e-434e-8d80-3d1a5fe3085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10924863815307617, 0.1071937084197998, 0.10734868049621582, 0.10463905334472656]\n",
      "[0.09789252281188965, 0.1138380765914917, 0.10732710361480713, 0.10660231113433838]\n",
      "[12.87924575805664, 1.8666038513183594, 1.8310279846191406, 1.7975082397460938]\n",
      "[0.43309688568115234, 0.38916015625, 0.3827180862426758, 0.3842477798461914]\n",
      "[0.12584829330444336, 0.12731456756591797, 0.11959362030029297, 0.1186528205871582]\n",
      "[0.2528400421142578, 0.25220680236816406, 0.24974441528320312, 0.24515342712402344]\n",
      "[6.668909072875977, 3.586162567138672, 3.1209278106689453, 3.126615524291992]\n",
      "                      corr        p_value\n",
      "self_attn.q_proj -0.953898   1.028537e-67\n",
      "self_attn.k_proj  0.200767   2.306658e-02\n",
      "self_attn.v_proj -0.574284   1.367413e-12\n",
      "self_attn.o_proj -0.610379   2.026282e-14\n",
      "mlp.gate_proj    -0.791431   1.034676e-28\n",
      "mlp.up_proj      -0.990653  6.973975e-111\n",
      "mlp.down_proj    -0.633419   1.028385e-15\n",
      "----------------------------------------\n",
      "                      corr       p_value\n",
      "self_attn.q_proj  0.985844  1.372792e-99\n",
      "self_attn.k_proj  0.768350  3.501566e-26\n",
      "self_attn.v_proj -0.691695  1.575564e-19\n",
      "self_attn.o_proj -0.249634  4.487217e-03\n",
      "mlp.gate_proj    -0.492198  3.618619e-09\n",
      "mlp.up_proj      -0.549880  1.784768e-11\n",
      "mlp.down_proj    -0.589168  2.564581e-13\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"fisher_data_1024_8_2024-12-28-11-58-49.json\"\n",
    "filename2 = \"modified_perplexitys_1024_8_2024-12-28-11-58-49_2.623046875.json\"\n",
    "cal_bits2fisher_pearson(filename1)\n",
    "print(\"----\"*10)\n",
    "cal_bits2perplexity_pearson(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c8c60-d1ef-4de8-8ce8-7a3ae0ebee0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
